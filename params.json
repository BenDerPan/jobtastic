{"tagline":"A Celery library that makes your user-responsive long-running jobs totally awesomer.","note":"Don't delete this file! It's used internally to help with page regeneration.","google":"","name":"Jobtastic","body":"# jobtastic- Celery tasks plus more awesome\r\n\r\nJobtastic is a [Celery](http://celeryproject.org) library\r\nthat makes your user-responsive long-running jobs\r\ntotally awesomer.\r\nCelery is the ubiquitous python job queueing tool\r\nand jobtastic is a python library\r\nthat adds useful features to your Celery tasks.\r\nSpecifically, these are features you probably want\r\nif the results of your jobs are expensive\r\nor if your users need to wait while they compute their results.\r\n\r\nJobtastic gives you goodies like:\r\n* Easy progress estimation/reporting\r\n* Job status feedback\r\n* Helper methods for gracefully handling a dead task broker\r\n  (`delay_or_run` and `delay_or_fail`)\r\n* A [celery jQuery plugin](https://github.com/PolicyStat/jquery-celery)\r\n  for easy client-side progress display\r\n* Result caching\r\n* [Thundering herd](http://en.wikipedia.org/wiki/Thundering_herd_problem) avoidance\r\n\r\nMake your Celery jobs more awesome with Jobtastic.\r\n\r\n## Why Jobtastic?\r\n\r\nIf you have user-facing tasks for which a user must wait,\r\nyou should try Jobtastic.\r\nIt's great for:\r\n* Complex reports\r\n* Graph generation\r\n* CSV exports\r\n* Any long-running, user-facing job\r\n\r\nYou could write all of the stuff yourself, but why?\r\n\r\n## Installation\r\n\r\n1. Get the project source and install it\r\n\r\n    $ pip install jobtastic\r\n\r\n## Creating Your First Task\r\n\r\nLet's take a look at an example task using Jobtastic:\r\n\r\n``` python\r\nfrom time import sleep\r\n\r\nfrom jobtastic import JobtasticTask\r\n\r\nclass LotsOfDivisionTask(JobtasticTask):\r\n\t\"\"\"\r\n\tDivision is hard. Make Celery do it a bunch.\r\n\t\"\"\"\r\n\t# These are the Task kwargs that matter for caching purposes\r\n\tsignificant_kwargs = [\r\n\t\t('numerators', str),\r\n\t\t('denominator', str),\r\n\t]\r\n\t# How long should we give a task before assuming it has failed?\r\n\therf_avoidance_timeout = 60  # Shouldn't take more than 60 seconds\r\n\t# How long we want to cache results with identical ``significant_kwargs``\r\n\tcache_duration = 0  # Cache these results forever. Math is pretty stable.\r\n\r\n\tdef calculate_result(self, numerators, denominators, **kwargs):\r\n\t\t\"\"\"\r\n\t\tMATH!!!\r\n\t\t\"\"\"\r\n\t\tresults = []\r\n\t\tdivisions_to_do = len(numerators)\r\n\t\t# Only actually update the progress in the backend every 10 operations\r\n\t\tupdate_frequency = 10\r\n\t\tfor count, divisors in enumerate(zip(numerators, denominators)):\r\n\t\t\tnumerator, denominator = divisors\r\n\t\t\tresults.append(numerator / denominator)\r\n\t\t\t# Let's let everyone know how we're doing\r\n\t\t\tself.update_progress(count, divisions_to_do, update_frequency=10)\r\n\t\t\t# Let's pretend that we're using the computers that landed us on the moon\r\n\t\t\tsleep(0.1)\r\n\r\n\t\treturn results\r\n```\r\n\r\nThis task is very trivial, but imagine doing something time-consuming instead\r\nof division (or just a ton of division) while a user waited. We wouldn't want\r\na double-clicker to cause this to happen twice concurrently, we wouldn't want\r\nto ever redo this work on the same numbers and we would want the user to have\r\nat least some idea of how long they'll need to wait. Just by setting those 4\r\nmember variables, we've done all of these things.\r\n\r\nBasically, creating a Celery task using Jobtastic is a matter of:\r\n\r\n1. Subclassing `jobtastic.task.JobtasticTask`\r\n2. Defining some required member variables\r\n3. Writing your `calculate_result` method\r\n  (instead of the normal Celery `run()` method)\r\n4. Sprinkling `update_progress()` calls in your `calculate_result()` method\r\n  to communicate progress\r\n\r\nNow, to use this task in your Django view, you'll do something like:\r\n\r\n``` python\r\nfrom django.shortcuts import render_to_response\r\n\r\nfrom my_app.tasks import LotsOfDivisionTask\r\n\r\ndef lets_divide(request):\r\n\t\"\"\"\r\n\tDo a set number of divisions and keep the user up to date on progress.\r\n\t\"\"\"\r\n\titerations = request.GET.get('iterations', 1000)  # That's a lot. Right?\r\n\tstep = 10\r\n\r\n\t# If we can't connect to the backend, let's not just 500. k?\r\n\tresult = LotsOfDivisionTask().delay_or_fail(\r\n\t\tnumerators=range(0, step * iterations * 2, step * 2),\r\n\t\tdenominators=range(1, step * iterations, step),\r\n\t)\r\n\r\n\treturn render_to_response(\r\n\t\t'my_app/lets_divide.html',\r\n\t\t{'task_id': result.task_id},\r\n\t)\r\n```\r\n\r\nThe `my_app/lets_divide.html` template will then use the `task_id` to query the task\r\nresult all asynchronous-like and keep the user up to date with what is\r\nhappening.\r\n\r\nFor [Flask](http://flask.pocoo.org/), you might do something like:\r\n\r\n``` python\r\nfrom flask import Flask, render_template\r\n\r\nfrom my_app.tasks import LotsOfDivisionTask\r\n\r\napp = Flask(__name__)\r\n\r\n@app.route(\"/\", methods=['GET'])\r\ndef lets_divide():\r\n\titerations = request.args.get('iterations', 1000)\r\n\tstep = 10\r\n\r\n\tresult = LotsOfDivisionTask().delay_or_fail(\r\n\t\tnumerators=range(0, step * iterations * 2, step * 2),\r\n\t\tdenominators=range(1, step * iterations, step),\r\n\t)\r\n\r\n\treturn render_template('my_app/lets_divide.html', task_id=request.task_id)\r\n```\r\n\r\n### Required Member Variables\r\n\r\n\"But wait, Wes. What the heck do those member variables actually do?\" You ask.\r\n\r\nFirstly. How the heck did you know my name?\r\nAnd B, why don't I tell you!?\r\n\r\n#### significant_kwargs\r\n\r\nThis is key to your caching magic. It's a list of 2-tuples containing the name\r\nof a kwarg plus a function to turn that kwarg in to a string. Jobtastic uses\r\nthese to determine if your task should have an identical result to another task\r\nrun. In our division example, any task with the same numerators and\r\ndenominators can be considered identical, so Jobtastic can do smart things.\r\n\r\n``` python\r\nsignificant_kwargs = [\r\n\t('numerators', str),\r\n\t('denominator', str),\r\n]\r\n```\r\n\r\nIf we were living in bizzaro world, and only the numerators mattered for\r\ndivision results, we could do something like:\r\n\r\n``` python\r\nsignificant_kwargs = [\r\n\t('numerators', str),\r\n]\r\n```\r\n\r\nNow tasks called with an identical list of numerators will share a result.\r\n\r\n#### herd_avoidance_timeout\r\n\r\nThis is the max number of seconds for which Jobtastic will wait for identical\r\ntask results to be determined. You want this number to be on the very high end\r\nof the amount of time you expect to wait (after a task starts) for the result.\r\nIf this number is hit, it's assumed that something bad happened to the other\r\ntask run (a worker failed) and we'll start calculating from the start.\r\n\r\n### Optional Member Variables\r\n\r\nThese let you tweak the behavior a bit, but you can usually ignore them\r\n(assuming you want to cache identical task results forever).\r\n\r\n#### cache_duration\r\n\r\nIf you want your results cached, set this to a positive number of seconds. This\r\nis the number of seconds for which identical jobs should try to just re-use the\r\ncached result. The default is -1, meaning don't do any caching. Remember,\r\n`JobtasticTask` uses your `signficant_kwargs` to determine what is identical.\r\n\r\n#### cache_prefix\r\n\r\nThis is an optional string used to represent tasks that should share cache\r\nresults and thundering herd avoidance. You should almost always not set this,\r\nand let Jobtastic use the `module.class` name. If you have two different tasks\r\nthat should share caching, or you have some very-odd cache key conflict, then\r\nyou can change this yourself. You probably shouldn't.\r\n\r\n### Method to Override\r\n\r\nOther than those two member variables, you'll probably want to actually do\r\nsomething in your task.\r\n\r\n#### calculate_result\r\n\r\nThis is where your magic happens. Do work here and return the result.\r\n\r\nYou'll almost definitely want to call `update_progress` periodically in this\r\nmethod so that your users get an idea of for how long they'll be waiting.\r\n\r\n### Progress feedback helper\r\n\r\nThis is the guy you'll want to call to provide nice progress feedback and\r\nestimation.\r\n\r\n#### update_progress\r\n\r\nIn your `calculate_result`, you'll want to periodically make calls like:\r\n\r\n``` python\r\nself.update_progress(work_done, total_work_to_do)\r\n```\r\n\r\nJobtastic takes care of handling timers to give estimates, and assumes that\r\nprogress will be roughly uniform across each work item.\r\n\r\nMost of the time, you really don't need ultra-granular progress updates and can\r\nafford to only give an update every `N` items completed. Since every update\r\nwould potentially hit your [CELERY_RESULT_BACKEND](\r\nhttp://celery.github.com/celery/configuration.html#celery-result-backend), and\r\nthat might cause a network trip, it's probably a good idea to use the optional\r\n`update_frequency` argument so that Jobtastic doesn't swamp your backend with\r\nupdated estimates no user will ever see.\r\n\r\nIn our division example, we're only actually updating the progress every 10\r\ndivision operations:\r\n\r\n``` python\r\n# Only actually update the progress in the backend every 10 operations\r\nupdate_frequency = 10\r\nfor count, divisors in enumerate(zip(numerators, denominators)):\r\n\tnumerator, denominator = divisors\r\n\tresults.append(numerator / denominator)\r\n\t# Let's let everyone know how we're doing\r\n\tself.update_progress(count, divisions_to_do, update_frequency=10)\r\n```\r\n\r\n## Using your JobtasticTask\r\n\r\nSometimes, your [Task\r\nBroker](http://celery.github.com/celery/configuration.html#broker-url) just up\r\nand dies (I'm looking at you, old versions of RabbitMQ). In production, calling\r\nstraight up `delay()` with a dead backend will throw an error that varies based\r\non what backend you're actually using. You probably don't want to just give\r\nyour user a generic 500 page if your broker is down, and it's not fun to handle\r\nthat exception every single place you might use Celery. Jobtastic has your\r\nback.\r\n\r\nIncluded are `delay_or_run` and `delay_or_fail` methods that handle a dead\r\nbackend and do something a little more production-friendly.\r\n\r\nNote: One very important caveat with `JobtasticTask` is that all of your arguments\r\nmust be keyword arguments.\r\n\r\nNote: This is a limitation of the current `signficant_kwargs`\r\nimplementation, and totally fixable if someone wants to submit a pull request.\r\n\r\n### delay_or_run\r\n\r\nIf your broker is behaving, this guy acts just like `delay()`. In the case that\r\nyour broker is down, though, it just goes ahead and runs the task in the\r\ncurrent process and skips sending the task to a worker. If you have a task that\r\nrealistically only takes a few seconds to run, this might be better than giving\r\nan error message.\r\n\r\n### delay_or_fail\r\n\r\nLike `delay_or_run`, this helps you handle a dead broker. Instead of running\r\nyour task in the current process, this actually generates a task result\r\nrepresenting the failure. This means that your client-side code can handle it\r\nlike any other failed task and do something nice for the user. Maybe send them\r\nflowers?\r\n\r\nFor tasks that might take a while or consume a lot of RAM, you're probably\r\nbetter off using this than `delay_or_run` because you don't want to make a\r\nresource problem worse.\r\n\r\n## Client Side Handling\r\n\r\nThat's all well and good on the server side,\r\nbut the biggest benefit of Jobtastic is useful user-facing feedback.\r\nThat means handling status checks using AJAX in the browser.\r\n\r\nThe easiest way to get rolling is to use our sister project,\r\n[jquery-celery](https://github.com/PolicyStat/jquery-celery).\r\nIt contains jQuery plugins that help you:\r\n* Poll for task status and handle the result\r\n* Display a progress bar using the info from the `PROGRESS` state.\r\n* Display tabular data using [DataTables](http://www.datatables.net/).\r\n\r\nIf you want to roll your own,\r\nthe general pattern is to poll a URL\r\n(such as the django-celery\r\n[task_status view](https://github.com/celery/django-celery/blob/master/djcelery/urls.py#L25) )\r\nwith your taskid to get JSON status information\r\nand then handle the possible states to keep the user informed.\r\n\r\nThe [jquery-celery](https://github.com/PolicyStat/jquery-celery/blob/master/src/celery.js)\r\njQuery plugin might still be useful as reference,\r\neven if you're rolling your own.\r\nIn general, you'll want to handle the following cases:\r\n\r\n### PENDING\r\n\r\nYour task is still waiting for a worker process.\r\nIt's generally useful to display something like \"Waiting for your task to begin\".\r\n\r\n### PROGRESS\r\n\r\nYour task has started and you've got a JSON object like:\r\n\r\n``` javascript\r\n{\r\n\t\"progress_percent\": 0,\r\n\t\"time_remaining\": 300\r\n}\r\n```\r\n\r\n`progress_percent` is a number between 0 and 100.\r\nIt's a good idea to give a different message if the percent is 0,\r\nbecause the time remaining estimate might not yet be well-calibrated.\r\n\r\n`time_remaining` is the number of seconds estimated to be left.\r\nIf there's no good estimate available, this value will be `-1`.\r\n\r\n### SUCCESS\r\n\r\nYou've got your data. It's time to display the result.\r\n\r\n### FAILURE\r\n\r\nSomething went wrong and the worker reported a failure.\r\nThis is a good time to either display a useful error message\r\n(if the user can be expected to correct the problem),\r\nor to ask the user to retry their task.\r\n\r\n### Non-200 Request\r\n\r\nThere are occasions where requesting the task status itself might error out.\r\nThis isn't a reflection on the worker itself,\r\nas it could be caused by any number of application errors.\r\nIn general, you probably want to try again if this happens,\r\nbut if it persists, you'll want to give your user feedback.\r\n\r\n## Is it Awesome?\r\n\r\nYes. Increasingly so.\r\n\r\n## A note on usage with Flask\r\n\r\nIf you're using Flask instead of Django, then the only currently-supported way\r\nto work with Jobtastic is with Memcached as your `CELERY_RESULT_BACKEND`. A\r\nmore generally-pythonic way of choosing/plugging cache backends is definitely a\r\ngoal, though, and pull requests\r\n(see [Issue 8](https://github.com/PolicyStat/jobtastic/issues/8)\r\nor suggestions are very welcome.\r\n\r\n## Project Status\r\n\r\nJobtastic is being in production on a large Django project with RabbitMQ as a\r\nbroker and Memcached as a result backend. If that's your configuration, then\r\nyou're in good shape. For other configurations, there are probably bugs that\r\nwill need to be ironed out.\r\n\r\nJobtastic is currently known to work with Django 1.3.x and Celery 2.5.x. The\r\ngoal is to support those versions and newer. Please file issues if there are\r\nproblems with newer versions of Django/Celery.\r\n\r\n## Non-affiliation\r\n\r\nThis project isn't affiliated with the awesome folks at the\r\n[Celery Project](http://www.celeryproject.org)\r\n(unless having a huge crush counts as affiliation).\r\nIt's a library that the folks at [PolicyStat](http://www.policystat.com)\r\nhave been using internally and decided to open source in the hopes it is useful to others.\r\n"}