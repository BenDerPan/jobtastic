<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Jobtastic by PolicyStat</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>Jobtastic</h1>
        <p>A Celery library that makes your user-responsive long-running jobs totally awesomer.</p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://github.com/PolicyStat/jobtastic" class="button fork"><strong>View On GitHub</strong></a>
        <div class="downloads">
          <span>Downloads:</span>
          <ul>
            <li><a href="https://github.com/PolicyStat/jobtastic/zipball/master" class="button">ZIP</a></li>
            <li><a href="https://github.com/PolicyStat/jobtastic/tarball/master" class="button">TAR</a></li>
          </ul>
        </div>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h1>
<a id="jobtastic--celery-tasks-plus-more-awesome" class="anchor" href="#jobtastic--celery-tasks-plus-more-awesome" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>jobtastic- Celery tasks plus more awesome</h1>

<p><a href="https://travis-ci.org/PolicyStat/jobtastic"><img src="https://travis-ci.org/PolicyStat/jobtastic.png?branch=master" alt="Build Status"></a></p>

<p>Jobtastic makes your user-responsive long-running
<a href="http://celeryproject.org">Celery</a> jobs totally awesomer.
Celery is the ubiquitous python job queueing tool
and jobtastic is a python library
that adds useful features to your Celery tasks.
Specifically, these are features you probably want
if the results of your jobs are expensive
or if your users need to wait while they compute their results.</p>

<p>Jobtastic gives you goodies like:</p>

<ul>
<li>Easy progress estimation/reporting</li>
<li>Job status feedback</li>
<li>Helper methods for gracefully handling a dead task broker
(<code>delay_or_eager</code> and <code>delay_or_fail</code>)</li>
<li>Super-easy result caching</li>
<li>
<a href="http://en.wikipedia.org/wiki/Thundering_herd_problem">Thundering herd</a> avoidance</li>
<li>Integration with a
<a href="https://github.com/PolicyStat/jquery-celery">celery jQuery plugin</a>
for easy client-side progress display</li>
<li>Memory leak detection in a task run</li>
</ul>

<p>Make your Celery jobs more awesome with Jobtastic.</p>

<h2>
<a id="why-jobtastic" class="anchor" href="#why-jobtastic" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Why Jobtastic?</h2>

<p>If you have user-facing tasks for which a user must wait,
you should try Jobtastic.
It's great for:</p>

<ul>
<li>Complex reports</li>
<li>Graph generation</li>
<li>CSV exports</li>
<li>Any long-running, user-facing job</li>
</ul>

<p>You could write all of the stuff yourself, but why?</p>

<h2>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

<ol>
<li>
<p>Install gcc and the python C headers
so that you can build <a href="https://github.com/giampaolo/psutil/blob/master/INSTALL.rst">psutil</a>.</p>

<p>On Ubuntu, that means running:</p>

<p><code>$ sudo apt-get install build-essential python-dev python2.7-dev python3.5-dev rabbitmq-server</code></p>

<p>On OS X, you'll need to run the "XcodeTools" installer.</p>
</li>
<li>
<p>Get the project source and install it</p>

<p><code>$ pip install jobtastic</code></p>
</li>
</ol>

<h2>
<a id="creating-your-first-task" class="anchor" href="#creating-your-first-task" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Creating Your First Task</h2>

<p>Let's take a look at an example task using Jobtastic:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> time <span class="pl-k">import</span> sleep

<span class="pl-k">from</span> jobtastic <span class="pl-k">import</span> JobtasticTask

<span class="pl-k">class</span> <span class="pl-en">LotsOfDivisionTask</span>(<span class="pl-e">JobtasticTask</span>):
    <span class="pl-s"><span class="pl-pds">"""</span></span>
<span class="pl-s">    Division is hard. Make Celery do it a bunch.</span>
<span class="pl-s">    <span class="pl-pds">"""</span></span>
    <span class="pl-c"># These are the Task kwargs that matter for caching purposes</span>
    significant_kwargs <span class="pl-k">=</span> [
        (<span class="pl-s"><span class="pl-pds">'</span>numerators<span class="pl-pds">'</span></span>, <span class="pl-c1">str</span>),
        (<span class="pl-s"><span class="pl-pds">'</span>denominators<span class="pl-pds">'</span></span>, <span class="pl-c1">str</span>),
    ]
    <span class="pl-c"># How long should we give a task before assuming it has failed?</span>
    herd_avoidance_timeout <span class="pl-k">=</span> <span class="pl-c1">60</span>  <span class="pl-c"># Shouldn't take more than 60 seconds</span>
    <span class="pl-c"># How long we want to cache results with identical ``significant_kwargs``</span>
    cache_duration <span class="pl-k">=</span> <span class="pl-c1">0</span>  <span class="pl-c"># Cache these results forever. Math is pretty stable.</span>
    <span class="pl-c"># Note: 0 means different things in different cache backends. RTFM for yours.</span>

    <span class="pl-k">def</span> <span class="pl-en">calculate_result</span>(<span class="pl-smi"><span class="pl-smi">self</span></span>, <span class="pl-smi">numerators</span>, <span class="pl-smi">denominators</span>, <span class="pl-k">**</span><span class="pl-smi">kwargs</span>):
        <span class="pl-s"><span class="pl-pds">"""</span></span>
<span class="pl-s">        MATH!!!</span>
<span class="pl-s">        <span class="pl-pds">"""</span></span>
        results <span class="pl-k">=</span> []
        divisions_to_do <span class="pl-k">=</span> <span class="pl-c1">len</span>(numerators)
        <span class="pl-c"># Only actually update the progress in the backend every 10 operations</span>
        update_frequency <span class="pl-k">=</span> <span class="pl-c1">10</span>
        <span class="pl-k">for</span> count, divisors <span class="pl-k">in</span> <span class="pl-c1">enumerate</span>(<span class="pl-c1">zip</span>(numerators, denominators)):
            numerator, denominator <span class="pl-k">=</span> divisors
            results.append(numerator <span class="pl-k">/</span> denominator)
            <span class="pl-c"># Let's let everyone know how we're doing</span>
            <span class="pl-v">self</span>.update_progress(
                count,
                divisions_to_do,
                <span class="pl-v">update_frequency</span><span class="pl-k">=</span>update_frequency,
            )
            <span class="pl-c"># Let's pretend that we're using the computers that landed us on the moon</span>
            sleep(<span class="pl-c1">0.1</span>)

        <span class="pl-k">return</span> results</pre></div>

<p>This task is very trivial,
but imagine doing something time-consuming instead of division
(or just a ton of division)
while a user waited.
We wouldn't want a double-clicker to cause this to happen twice concurrently,
we wouldn't want to ever redo this work on the same numbers
and we would want the user to have at least some idea
of how long they'll need to wait.
Just by setting those 3 member variables,
we've done all of these things.</p>

<p>Basically, creating a Celery task using Jobtastic is a matter of:</p>

<ol>
<li>Subclassing <code>jobtastic.JobtasticTask</code>
</li>
<li>Defining some required member variables</li>
<li>Writing your <code>calculate_result</code> method
(instead of the normal Celery <code>run()</code> method)</li>
<li>Sprinkling <code>update_progress()</code> calls in your <code>calculate_result()</code> method
to communicate progress</li>
</ol>

<p>Now, to use this task in your Django view, you'll do something like:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> django.shortcuts <span class="pl-k">import</span> render_to_response

<span class="pl-k">from</span> my_app.tasks <span class="pl-k">import</span> LotsOfDivisionTask

<span class="pl-k">def</span> <span class="pl-en">lets_divide</span>(<span class="pl-smi">request</span>):
    <span class="pl-s"><span class="pl-pds">"""</span></span>
<span class="pl-s">    Do a set number of divisions and keep the user up to date on progress.</span>
<span class="pl-s">    <span class="pl-pds">"""</span></span>
    iterations <span class="pl-k">=</span> request.<span class="pl-c1">GET</span>.get(<span class="pl-s"><span class="pl-pds">'</span>iterations<span class="pl-pds">'</span></span>, <span class="pl-c1">1000</span>)  <span class="pl-c"># That's a lot. Right?</span>
    step <span class="pl-k">=</span> <span class="pl-c1">10</span>

    <span class="pl-c"># If we can't connect to the backend, let's not just 500. k?</span>
    result <span class="pl-k">=</span> LotsOfDivisionTask.delay_or_fail(
        <span class="pl-v">numerators</span><span class="pl-k">=</span><span class="pl-c1">range</span>(<span class="pl-c1">0</span>, step <span class="pl-k">*</span> iterations <span class="pl-k">*</span> <span class="pl-c1">2</span>, step <span class="pl-k">*</span> <span class="pl-c1">2</span>),
        <span class="pl-v">denominators</span><span class="pl-k">=</span><span class="pl-c1">range</span>(<span class="pl-c1">1</span>, step <span class="pl-k">*</span> iterations, step),
    )

    <span class="pl-k">return</span> render_to_response(
        <span class="pl-s"><span class="pl-pds">'</span>my_app/lets_divide.html<span class="pl-pds">'</span></span>,
        {<span class="pl-s"><span class="pl-pds">'</span>task_id<span class="pl-pds">'</span></span>: result.task_id},
    )</pre></div>

<p>The <code>my_app/lets_divide.html</code> template will then use the <code>task_id</code>
to query the task result all asynchronous-like
and keep the user up to date with what is happening.</p>

<p>For <a href="http://flask.pocoo.org/">Flask</a>, you might do something like:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> flask <span class="pl-k">import</span> Flask, render_template

<span class="pl-k">from</span> my_app.tasks <span class="pl-k">import</span> LotsOfDivisionTask

app <span class="pl-k">=</span> Flask(<span class="pl-c1">__name__</span>)

<span class="pl-en">@app.route</span>(<span class="pl-s"><span class="pl-pds">"</span>/<span class="pl-pds">"</span></span>, <span class="pl-v">methods</span><span class="pl-k">=</span>[<span class="pl-s"><span class="pl-pds">'</span>GET<span class="pl-pds">'</span></span>])
<span class="pl-k">def</span> <span class="pl-en">lets_divide</span>():
    iterations <span class="pl-k">=</span> request.args.get(<span class="pl-s"><span class="pl-pds">'</span>iterations<span class="pl-pds">'</span></span>, <span class="pl-c1">1000</span>)
    step <span class="pl-k">=</span> <span class="pl-c1">10</span>

    result <span class="pl-k">=</span> LotsOfDivisionTask.delay_or_fail(
        <span class="pl-v">numerators</span><span class="pl-k">=</span><span class="pl-c1">range</span>(<span class="pl-c1">0</span>, step <span class="pl-k">*</span> iterations <span class="pl-k">*</span> <span class="pl-c1">2</span>, step <span class="pl-k">*</span> <span class="pl-c1">2</span>),
        <span class="pl-v">denominators</span><span class="pl-k">=</span><span class="pl-c1">range</span>(<span class="pl-c1">1</span>, step <span class="pl-k">*</span> iterations, step),
    )

    <span class="pl-k">return</span> render_template(<span class="pl-s"><span class="pl-pds">'</span>my_app/lets_divide.html<span class="pl-pds">'</span></span>, <span class="pl-v">task_id</span><span class="pl-k">=</span>result.task_id)</pre></div>

<h3>
<a id="required-member-variables" class="anchor" href="#required-member-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Required Member Variables</h3>

<p>"But wait, Wes. What the heck do those member variables actually do?" You ask.</p>

<p>Firstly. How the heck did you know my name?</p>

<p>And B, why don't I tell you!?</p>

<h4>
<a id="significant_kwargs" class="anchor" href="#significant_kwargs" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>significant_kwargs</h4>

<p>This is key to your caching magic.
It's a list of 2-tuples containing the name of a kwarg
plus a function to turn that kwarg in to a string.
Jobtastic uses these to determine if your task
should have an identical result to another task run.
In our division example,
any task with the same numerators and denominators can be considered identical,
so Jobtastic can do smart things.</p>

<div class="highlight highlight-source-python"><pre>significant_kwargs <span class="pl-k">=</span> [
    (<span class="pl-s"><span class="pl-pds">'</span>numerators<span class="pl-pds">'</span></span>, <span class="pl-c1">str</span>),
    (<span class="pl-s"><span class="pl-pds">'</span>denominators<span class="pl-pds">'</span></span>, <span class="pl-c1">str</span>),
]</pre></div>

<p>If we were living in bizzaro world,
and only the numerators mattered for division results,
we could do something like:</p>

<div class="highlight highlight-source-python"><pre>significant_kwargs <span class="pl-k">=</span> [
    (<span class="pl-s"><span class="pl-pds">'</span>numerators<span class="pl-pds">'</span></span>, <span class="pl-c1">str</span>),
]</pre></div>

<p>Now tasks called with an identical list of numerators will share a result.</p>

<h4>
<a id="herd_avoidance_timeout" class="anchor" href="#herd_avoidance_timeout" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>herd_avoidance_timeout</h4>

<p>This is the max number of seconds for which Jobtastic will wait
for identical task results to be determined.
You want this number to be on the very high end
of the amount of time you expect to wait
(after a task starts)
for the result.
If this number is hit,
it's assumed that something bad happened to the other task run
(a worker failed)
and we'll start calculating from the start.</p>

<h3>
<a id="optional-member-variables" class="anchor" href="#optional-member-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optional Member Variables</h3>

<p>These let you tweak the default behavior.
Most often, you'll just be setting the <code>cache_duration</code>
to enable result caching.</p>

<h4>
<a id="cache_duration" class="anchor" href="#cache_duration" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>cache_duration</h4>

<p>If you want your results cached,
set this to a non-negative number of seconds.
This is the number of seconds for which identical jobs
should try to just re-use the cached result.
The default is -1,
meaning don't do any caching.
Remember,
<code>JobtasticTask</code> uses your <code>significant_kwargs</code> to determine what is identical.</p>

<h4>
<a id="cache_prefix" class="anchor" href="#cache_prefix" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>cache_prefix</h4>

<p>This is an optional string used to represent tasks
that should share cache results and thundering herd avoidance.
You should almost never set this yourself,
and instead should let Jobtastic use the <code>module.class</code> name.
If you have two different tasks that should share caching,
or you have some very-odd cache key conflict,
then you can change this yourself.
You probably don't need to.</p>

<h4>
<a id="memleak_threshold" class="anchor" href="#memleak_threshold" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>memleak_threshold</h4>

<p>Set this value to monitor your tasks
for any runs that increase the memory usage
by more than this number of Megabytes
(the SI definition).
Individual task runs that increase resident memory
by more than this threshold
get some extra logging
in order to help you debug the problem.
By default, it logs the following via standard Celery logging:</p>

<ul>
<li>The memory increase</li>
<li>The memory starting value</li>
<li>The memory ending value</li>
<li>The task's kwargs</li>
</ul>

<p>You then grep for <code>Jobtastic:memleak memleak_detected</code> in your logs
to identify offending tasks.</p>

<p>If you'd like to customize this behavior,
you can override the <code>warn_of_memory_leak</code> method in your own <code>Task</code>.</p>

<h3>
<a id="method-to-override" class="anchor" href="#method-to-override" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Method to Override</h3>

<p>Other than tweaking the member variables,
you'll probably want to actually, you know,
<em>do something</em> in your task.</p>

<h4>
<a id="calculate_result" class="anchor" href="#calculate_result" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>calculate_result</h4>

<p>This is where your magic happens.
Do work here and return the result.</p>

<p>You'll almost definitely want to
call <code>update_progress</code> periodically in this method
so that your users get an idea of for how long they'll be waiting.</p>

<h3>
<a id="progress-feedback-helper" class="anchor" href="#progress-feedback-helper" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Progress feedback helper</h3>

<p>This is the guy you'll want to call
to provide nice progress feedback and estimation.</p>

<h4>
<a id="update_progress" class="anchor" href="#update_progress" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>update_progress</h4>

<p>In your <code>calculate_result</code>,
you'll want to periodically make calls like:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-v">self</span>.update_progress(work_done, total_work_to_do)</pre></div>

<p>Jobtastic takes care of handling timers to give estimates,
and assumes that progress will be roughly uniform across each work item.</p>

<p>Most of the time,
you really don't need ultra-granular progress updates
and can afford to only give an update every <code>N</code> items completed.
Since every update would potentially hit your
<a href="http://celery.github.com/celery/configuration.html#celery-result-backend">CELERY_RESULT_BACKEND</a>,
and that might cause a network trip,
it's probably a good idea to use the optional <code>update_frequency</code> argument
so that Jobtastic doesn't swamp your backend
with updated estimates no user will ever see.</p>

<p>In our division example,
we're only actually updating the progress every 10 division operations:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-c"># Only actually update the progress in the backend every 10 operations</span>
update_frequency <span class="pl-k">=</span> <span class="pl-c1">10</span>
<span class="pl-k">for</span> count, divisors <span class="pl-k">in</span> <span class="pl-c1">enumerate</span>(<span class="pl-c1">zip</span>(numerators, denominators)):
    numerator, denominator <span class="pl-k">=</span> divisors
    results.append(numerator <span class="pl-k">/</span> denominator)
    <span class="pl-c"># Let's let everyone know how we're doing</span>
    <span class="pl-v">self</span>.update_progress(count, divisions_to_do, <span class="pl-v">update_frequency</span><span class="pl-k">=</span><span class="pl-c1">10</span>)</pre></div>

<h2>
<a id="using-your-jobtastictask" class="anchor" href="#using-your-jobtastictask" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using your JobtasticTask</h2>

<p>Sometimes,
your <a href="http://celery.github.com/celery/configuration.html#broker-url">Task Broker</a>
just up and dies
(I'm looking at you, old versions of RabbitMQ).
In production,
calling straight up <code>delay()</code> with a dead backend
will throw an error that varies based on what backend you're actually using.
You probably don't want to just give your user a generic 500 page
if your broker is down,
and it's not fun to handle that exception every single place
you might use Celery.
Jobtastic has your back.</p>

<p>Included are <code>delay_or_eager</code> and <code>delay_or_fail</code> methods
that handle a dead backend
and do something a little more production-friendly.</p>

<p>Note: One very important caveat with <code>JobtasticTask</code> is that
all of your arguments must be keyword arguments.</p>

<p>Note: This is a limitation of the current <code>significant_kwargs</code> implementation,
and totally fixable if someone wants to submit a pull request.</p>

<h3>
<a id="delay_or_eager" class="anchor" href="#delay_or_eager" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>delay_or_eager</h3>

<p>If your broker is behaving itself,
this guy acts just like <code>delay()</code>.
In the case that your broker is down,
though,
it just goes ahead and runs the task in the current process
and skips sending the task to a worker.
You get back a nice shiny <code>EagerResult</code> object,
which behaves just like the <code>AsyncResult</code> you were expecting.
If you have a task that realistically only takes a few seconds to run,
this might be better than giving yours users an error message.</p>

<h3>
<a id="delay_or_fail" class="anchor" href="#delay_or_fail" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>delay_or_fail</h3>

<p>Like <code>delay_or_eager</code>,
this helps you handle a dead broker.
Instead of running your task in the current process,
this actually generates a task result representing the failure.
This means that your client-side code can handle it
like any other failed task
and do something nice for the user.
Maybe send them a fruit basket?</p>

<p>For tasks that might take a while
or consume a lot of RAM,
you're probably better off using this than <code>delay_or_eager</code>
because you don't want to make a resource problem worse.</p>

<h2>
<a id="client-side-handling" class="anchor" href="#client-side-handling" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Client Side Handling</h2>

<p>That's all well and good on the server side,
but the biggest benefit of Jobtastic is useful user-facing feedback.
That means handling status checks using AJAX in the browser.</p>

<p>The easiest way to get rolling is to use our sister project,
<a href="https://github.com/PolicyStat/jquery-celery">jquery-celery</a>.
It contains jQuery plugins that help you:</p>

<ul>
<li>Poll for task status and handle the result</li>
<li>Display a progress bar using the info from the <code>PROGRESS</code> state.</li>
<li>Display tabular data using <a href="http://www.datatables.net/">DataTables</a>.</li>
</ul>

<p>If you want to roll your own,
the general pattern is to poll a URL
(such as the django-celery
<a href="https://github.com/celery/django-celery/blob/master/djcelery/urls.py#L25">task_status view</a> )
with your taskid to get JSON status information
and then handle the possible states to keep the user informed.</p>

<p>The <a href="https://github.com/PolicyStat/jquery-celery/blob/master/src/celery.js">jquery-celery</a>
jQuery plugin might still be useful as reference,
even if you're rolling your own.
In general, you'll want to handle the following cases:</p>

<h3>
<a id="pending" class="anchor" href="#pending" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>PENDING</h3>

<p>Your task is still waiting for a worker process.
It's generally useful to display something like "Waiting for your task to begin".</p>

<h3>
<a id="progress" class="anchor" href="#progress" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>PROGRESS</h3>

<p>Your task has started and you've got a JSON object like:</p>

<div class="highlight highlight-source-js"><pre>{
    <span class="pl-s"><span class="pl-pds">"</span>progress_percent<span class="pl-pds">"</span></span><span class="pl-k">:</span> <span class="pl-c1">0</span>,
    <span class="pl-s"><span class="pl-pds">"</span>time_remaining<span class="pl-pds">"</span></span><span class="pl-k">:</span> <span class="pl-c1">300</span>
}</pre></div>

<p><code>progress_percent</code> is a number between 0 and 100.
It's a good idea to give a different message if the percent is 0,
because the time remaining estimate might not yet be well-calibrated.</p>

<p><code>time_remaining</code> is the number of seconds estimated to be left.
If there's no good estimate available, this value will be <code>-1</code>.</p>

<h3>
<a id="success" class="anchor" href="#success" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SUCCESS</h3>

<p>You've got your data. It's time to display the result.</p>

<h3>
<a id="failure" class="anchor" href="#failure" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>FAILURE</h3>

<p>Something went wrong and the worker reported a failure.
This is a good time to either display a useful error message
(if the user can be expected to correct the problem),
or to ask the user to retry their task.</p>

<h3>
<a id="non-200-request" class="anchor" href="#non-200-request" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Non-200 Request</h3>

<p>There are occasions where requesting the task status itself might error out.
This isn't a reflection on the worker itself,
as it could be caused by any number of application errors.
In general, you probably want to try again if this happens,
but if it persists, you'll want to give your user feedback.</p>

<h2>
<a id="running-the-test-suite" class="anchor" href="#running-the-test-suite" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running The Test Suite</h2>

<p>We use <a href="https://tox.readthedocs.org/en/latest/">tox</a>
to run our tests against various combinations
of python/Django/Celery.
We only officially support
the combinations listed in our <code>.travis.yml</code> file,
but we're working on
(<a href="https://github.com/PolicyStat/jobtastic/issues/33">Issue 33</a>)
supporting everything defined in <code>tox.ini</code>.
Until then,
you can run tests against supported combos with:</p>

<pre><code>$ pip install tox
$ tox -e py27-django1.8.X-djangocelery3.1.X-celery3.1.X
</code></pre>

<p>Our test suite currently only tests usage with Django,
which is definitely a <a href="https://github.com/PolicyStat/jobtastic/issues/15">bug</a>.
Especially if you use Jobtastic with Flask,
we would love a pull request.</p>

<h2>
<a id="dynamic-time-estimates-via-jobtasticmixins" class="anchor" href="#dynamic-time-estimates-via-jobtasticmixins" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dynamic Time Estimates via JobtasticMixins</h2>

<p>Have tasks whose duration is difficult to estimate
or that doesn't have smooth progress?
<a href="https://github.com/abbasovalex/JobtasticMixins">JobtasticMixins</a>
to the rescue!</p>

<p>JobtasticMixins provides an <code>AVGTimeRedis</code> mixin
that stores duration date in a Redis backend.
It then automatically uses this stored historical data
to calculate an estimate.
For more details,
check out <a href="https://github.com/abbasovalex/JobtasticMixins">JobtasticMixins</a>
on github.</p>

<h2>
<a id="is-it-awesome" class="anchor" href="#is-it-awesome" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Is it Awesome?</h2>

<p>Yes. Increasingly so.</p>

<h2>
<a id="project-status" class="anchor" href="#project-status" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Project Status</h2>

<p>Jobtastic is currently known to work
with Django 1.6+ and Celery 3.1.X
The goal is to support those versions and newer.
Please file issues if there are problems
with newer versions of Django/Celery.</p>

<h3>
<a id="a-note-on-usage-with-flask" class="anchor" href="#a-note-on-usage-with-flask" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>A note on usage with Flask</h3>

<p>If you're using Flask instead of Django,
then the only currently-supported way to work with Jobtastic
is with Memcached as your <code>CELERY_RESULT_BACKEND</code>.
A more generally-pythonic way of choosing/plugging cache backends
is definitely a goal,
though,
and pull requests
(see <a href="https://github.com/PolicyStat/jobtastic/issues/8">Issue 8</a> )
or suggestions are very welcome.
We'd also love some Flask-specific tests!</p>

<h2>
<a id="non-affiliation" class="anchor" href="#non-affiliation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Non-affiliation</h2>

<p>This project isn't affiliated with the awesome folks at the
<a href="http://www.celeryproject.org">Celery Project</a>
(unless having a huge crush counts as affiliation).
It's a library that the folks at <a href="http://www.policystat.com">PolicyStat</a>
have been using internally
and decided to open source in the hopes it is useful to others.</p>
      </section>
      <footer>
        <p>Project maintained by <a href="https://github.com/PolicyStat">PolicyStat</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
